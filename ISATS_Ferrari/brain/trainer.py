import os
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import sys

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from brain.models import HybridCNN_LSTM

# ==========================================
# ğŸ‹ï¸ Deep Eyes Training System
# ==========================================

# ì„¤ì •
SEQ_LENGTH = 60   # ê³¼ê±° 60ì¼(ë˜ëŠ” 60ê°œ ìº”ë“¤)ì„ ë³´ê³  íŒë‹¨
PREDICT_DAY = 1   # ë‹¤ìŒ 1ì¼ ë’¤ë¥¼ ì˜ˆì¸¡
BATCH_SIZE = 32
EPOCHS = 5
LEARNING_RATE = 0.001
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class StockDataset(Dataset):
    def __init__(self, data_dir, market="KR", limit_files=20):
        self.samples = []
        self.targets = []
        
        target_dir = os.path.join(data_dir, market)
        
        if not os.path.exists(target_dir):
            print(f"âŒ [{market}] ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {target_dir}")
            return
            
        files = [f for f in os.listdir(target_dir) if f.endswith('.csv')]
        
        if not files:
            print(f"âŒ [{market}] CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì±„êµ´ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
            return
        
        print(f"ğŸ“š [{market}] ë°ì´í„° ë¡œë”© ì¤‘... (ìµœëŒ€ {limit_files}ê°œ ì¢…ëª© í•™ìŠµ)")
        
        for file in tqdm(files[:limit_files]): # ë„ˆë¬´ ë§ìœ¼ë©´ ë©”ëª¨ë¦¬ í„°ì§€ë¯€ë¡œ ì œí•œ
            path = os.path.join(target_dir, file)
            try:
                df = pd.read_csv(path)
                
                # ë°ì´í„° ì „ì²˜ë¦¬ (ì •ê·œí™”)
                cols = ['Open', 'High', 'Low', 'Close', 'Volume']
                if not all(c in df.columns for c in cols): 
                    continue
                
                # NaN ì œê±°
                df = df.dropna()
                if len(df) < SEQ_LENGTH + PREDICT_DAY:
                    continue
                
                # ê°„ë‹¨í•œ MinMax Scaling
                df_norm = (df[cols] - df[cols].min()) / (df[cols].max() - df[cols].min() + 1e-6)
                
                data = df_norm.values
                close_prices = df['Close'].values # ì›ë³¸ ì¢…ê°€
                
                # ì‹œí€€ìŠ¤ ìƒì„±
                for i in range(len(data) - SEQ_LENGTH - PREDICT_DAY):
                    x = data[i : i+SEQ_LENGTH]
                    
                    # ë¼ë²¨ë§: ë‚´ì¼ ì¢…ê°€ê°€ ì˜¤ëŠ˜ ì¢…ê°€ë³´ë‹¤ 2% ì´ìƒ ì˜¤ë¥´ë©´ 1
                    today_close = close_prices[i + SEQ_LENGTH - 1]
                    tomorrow_close = close_prices[i + SEQ_LENGTH]
                    
                    if tomorrow_close > today_close * 1.02:
                        y = 1.0
                    else:
                        y = 0.0
                        
                    self.samples.append(x)
                    self.targets.append(y)
            except Exception as e:
                continue
                
        if len(self.samples) > 0:
            self.samples = torch.FloatTensor(np.array(self.samples))
            self.targets = torch.FloatTensor(np.array(self.targets)).unsqueeze(1)
            print(f"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ: ì´ {len(self.samples)}ê°œ ìƒ˜í”Œ")
        else:
            print(f"âŒ ìœ íš¨í•œ ìƒ˜í”Œì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        return self.samples[idx], self.targets[idx]

def train():
    print(f"ğŸš€ [Training] Deep Eyes í•™ìŠµ ì‹œì‘ (Device: {DEVICE})")
    
    # 1. ë°ì´í„° ë¡œë“œ
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    data_dir = os.path.join(base_dir, "data")
    
    # í•œêµ­ ì£¼ì‹ ë°ì´í„°ë¡œ í•™ìŠµ
    dataset = StockDataset(data_dir, market="KR", limit_files=20) 
    if len(dataset) == 0:
        print("âŒ í•™ìŠµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì±„êµ´(mass_data_miner)ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
        return

    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
    
    # 2. ëª¨ë¸ ì´ˆê¸°í™”
    model = HybridCNN_LSTM().to(DEVICE)
    criterion = nn.BCELoss() # ì´ì§„ ë¶„ë¥˜
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    # 3. í•™ìŠµ ë£¨í”„
    model.train()
    for epoch in range(EPOCHS):
        total_loss = 0
        correct = 0
        total = 0
        
        progress = tqdm(dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}")
        for X, y in progress:
            X, y = X.to(DEVICE), y.to(DEVICE)
            
            optimizer.zero_grad()
            output = model(X)
            loss = criterion(output, y)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
            # ì •í™•ë„ ê³„ì‚°
            predicted = (output > 0.5).float()
            correct += (predicted == y).sum().item()
            total += y.size(0)
            
            progress.set_postfix({'Loss': loss.item()})
            
        avg_loss = total_loss / len(dataloader)
        acc = correct / total * 100
        print(f"   ğŸ“Š Epoch {epoch+1} ê²°ê³¼ -> Loss: {avg_loss:.4f} | Accuracy: {acc:.2f}%")

    # 4. ëª¨ë¸ ì €ì¥
    save_dir = os.path.join(base_dir, "brain", "weights")
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, "deep_eyes_v2_latest.pth")
    torch.save(model.state_dict(), save_path)
    
    print("\nğŸ‰ [Complete] í•™ìŠµ ì™„ë£Œ!")
    print(f"   ğŸ’¾ ëª¨ë¸ ì €ì¥ë¨: {save_path}")
    print("   -> ì´ì œ main.pyë¥¼ ì‹¤í–‰í•˜ë©´ ì´ ë‘ë‡Œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    train()
